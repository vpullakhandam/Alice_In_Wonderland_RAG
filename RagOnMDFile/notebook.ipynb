{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "407e2cf0",
   "metadata": {},
   "source": [
    "Here's the diagram for the process : [rag_image](mermaid_rag.png)\n",
    "Link to the Streamlit application : [rag_application](https://alice-in-wonderland-rag.streamlit.app/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9911ff23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Install dependencies\n",
    "\n",
    "%pip install langchain langchain-community langchain-huggingface langchain-google-genai --quiet\n",
    "%pip install chromadb sentence-transformers FlagEmbedding huggingface_hub --quiet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7225c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Imports\n",
    "import os, re, json\n",
    "from pathlib import Path\n",
    "\n",
    "# LangChain components\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Reranker\n",
    "from FlagEmbedding import FlagReranker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8600151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Authentication (Hugging Face + Gemini key)\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Hugging Face login\n",
    "HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(HF_TOKEN)\n",
    "\n",
    "# Gemini API key\n",
    "GOOGLE_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "assert GOOGLE_API_KEY, \"Gemini API Key not found!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaf33c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Instructor/OpenRouter client ready.\n"
     ]
    }
   ],
   "source": [
    "# (NEW) Instructor client for OpenRouter — add right after STEP 3\n",
    "import os\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "\n",
    "# Safe re-init: only creates if not already present\n",
    "try:\n",
    "    or_client\n",
    "except NameError:\n",
    "    OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "    assert OPENROUTER_API_KEY, \"OpenRouter API Key not found! Set OPENROUTER_API_KEY in your .env\"\n",
    "    or_client = instructor.from_openai(\n",
    "        OpenAI(base_url=\"https://openrouter.ai/api/v1\", api_key=OPENROUTER_API_KEY),\n",
    "        mode=instructor.Mode.JSON  # enforce JSON schema + auto-retries\n",
    "    )\n",
    "\n",
    "# #printing\n",
    "print(\"✅ Instructor/OpenRouter client ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "613ff31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ Summarizing chunks with OpenRouter gpt-oss-20b (token-aware splitting)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Example 3 Chunks ###\n",
      "{\n",
      "  \"content\": \"**_ START OF THE PROJECT GUTENBERG EBOOK ALICE'S ADVENTURES IN WONDERLAND _**\\n\\nContents\\n\\nCHAPTER I. Down the Rabbit-Hole\\nCHAPTER II. The Pool of Tears\\nCHAPTER III. A Caucus-Race and a Long Tale\\nCHAPTER IV. The Rabbit Sends in a Little Bill\\nCHAPTER V. Advice from a Caterpillar\\nCHAPTER VI. Pig and Pepper\\nCHAPTER VII. A Mad Tea-Party\\nCHAPTER VIII. The Queen’s Croquet-Ground\\nCHAPTER IX. The Mock Turtle’s Story\\nCHAPTER X. The Lobster Quadrille\\nCHAPTER XI. Who Stole the Tarts?\\nCHAPTER XII. Alice’s Evidence\\n\\nCHAPTER I.\\nDown the Rabbit-Hole\\n\\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once or twice she had peeped into\\nthe book her sister was reading, but it had no pictures or\\nconversations in it, “and what is the use of a book,” thought Alice\\n“without pictures or conversations?”\\n\\nSo she was considering in her own mind (as well as she could, for the\\nhot day made her feel very sleepy and stupid), whether the pleasure of\\nmaking a daisy-chain would be worth the trouble of getting up and\\npicking the daisies, when suddenly a White Rabbit with pink eyes ran\\nclose by her.\\n\\nThere was nothing so _very_ remarkable in that; nor did Alice think it\\nso _very_ much out of the way to hear the Rabbit say to itself, “Oh\\ndear! Oh dear! I shall be late!” (when she thought it over afterwards,\\nit occurred to her that she ought to have wondered at this, but at the\\ntime it all seemed quite natural); but when the Rabbit actually _took a\\nwatch out of its waistcoat-pocket_, and looked at it, and then hurried\\non, Alice started to her feet, for it flashed across her mind that she\\nhad never before seen a rabbit with either a waistcoat-pocket, or a\\nwatch to take out of it, and burning with curiosity, she ran across the\\nfield after it, and fortunately was just in time to see it pop down a\\nlarge rabbit-hole under the hedge.\\n\\nIn another moment down went Alice after it, never once considering how\\nin the world she was to get out again.\\n\\nThe rabbit-hole went straight on like a tunnel for some way, and then\\ndipped suddenly down, so suddenly that Alice had not a moment to think\\nabout stopping herself before she found herself falling down a very\\ndeep well.\",\n",
      "  \"metadata\": {\n",
      "    \"source\": \"alice_in_wonderland.md\",\n",
      "    \"chapter_number\": null,\n",
      "    \"chapter_title\": null,\n",
      "    \"start_index\": 1,\n",
      "    \"chunk_number\": 0,\n",
      "    \"chunk_summary\": \"Alice, bored while sitting with her sister, muses that “what is the use of a book, without pictures or conversations?” before a “White Rabbit with pink eyes” rushes past, exclaiming “Oh dear! Oh dear! I shall be late!” and pulls out a watch from its waistcoat‑pocket, a sight that “flashed across her mind” and sparks her curiosity. She follows the rabbit into a large rabbit‑hole, and, without a second thought, falls “down a very deep well,” setting the stage for her fantastical adventure.\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"content\": \"In another moment down went Alice after it, never once considering how\\nin the world she was to get out again.\\n\\nThe rabbit-hole went straight on like a tunnel for some way, and then\\ndipped suddenly down, so suddenly that Alice had not a moment to think\\nabout stopping herself before she found herself falling down a very\\ndeep well.\\n\\nEither the well was very deep, or she fell very slowly, for she had\\nplenty of time as she went down to look about her and to wonder what\\nwas going to happen next. First, she tried to look down and make out\\nwhat she was coming to, but it was too dark to see anything; then she\\nlooked at the sides of the well, and noticed that they were filled with\\ncupboards and book-shelves; here and there she saw maps and pictures\\nhung upon pegs. She took down a jar from one of the shelves as she\\npassed; it was labelled “ORANGE MARMALADE”, but to her great\\ndisappointment it was empty: she did not like to drop the jar for fear\\nof killing somebody underneath, so managed to put it into one of the\\ncupboards as she fell past it.\\n\\n“Well!” thought Alice to herself, “after such a fall as this, I shall\\nthink nothing of tumbling down stairs! How brave they’ll all think me\\nat home! Why, I wouldn’t say anything about it, even if I fell off the\\ntop of the house!” (Which was very likely true.)\\n\\nDown, down, down. Would the fall _never_ come to an end? “I wonder how\\nmany miles I’ve fallen by this time?” she said aloud. “I must be\\ngetting somewhere near the centre of the earth. Let me see: that would\\nbe four thousand miles down, I think—” (for, you see, Alice had learnt\\nseveral things of this sort in her lessons in the schoolroom, and\\nthough this was not a _very_ good opportunity for showing off her\\nknowledge, as there was no one to listen to her, still it was good\\npractice to say it over) “—yes, that’s about the right distance—but\\nthen I wonder what Latitude or Longitude I’ve got to?” (Alice had no\\nidea what Latitude was, or Longitude either, but thought they were nice\\ngrand words to say.)\",\n",
      "  \"metadata\": {\n",
      "    \"source\": \"alice_in_wonderland.md\",\n",
      "    \"chapter_number\": null,\n",
      "    \"chapter_title\": null,\n",
      "    \"start_index\": -1,\n",
      "    \"chunk_number\": 1,\n",
      "    \"chunk_summary\": \"Alice falls down a rabbit‑hole that turns into a deep well, where she notices cupboards, bookshelves, maps, and an empty jar labeled “ORANGE MARMALADE” that she carefully hides away. While descending, she muses aloud, “Well!” thought Alice to herself, “after such a fall as this, I shall think nothing of tumbling down stairs!” and wonders, “I wonder how many miles I’ve fallen by this time?”, even joking about reaching the centre of the earth and pondering “Latitude or Longitude I’ve got to?” as she drifts deeper.\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"content\": \"Presently she began again. “I wonder if I shall fall right _through_\\nthe earth! How funny it’ll seem to come out among the people that walk\\nwith their heads downward! The Antipathies, I think—” (she was rather\\nglad there _was_ no one listening, this time, as it didn’t sound at all\\nthe right word) “—but I shall have to ask them what the name of the\\ncountry is, you know. Please, Ma’am, is this New Zealand or Australia?”\\n(and she tried to curtsey as she spoke—fancy _curtseying_ as you’re\\nfalling through the air! Do you think you could manage it?) “And what\\nan ignorant little girl she’ll think me for asking! No, it’ll never do\\nto ask: perhaps I shall see it written up somewhere.”\\n\\nDown, down, down. There was nothing else to do, so Alice soon began\\ntalking again. “Dinah’ll miss me very much to-night, I should think!”\\n(Dinah was the cat.) “I hope they’ll remember her saucer of milk at\\ntea-time. Dinah my dear! I wish you were down here with me! There are\\nno mice in the air, I’m afraid, but you might catch a bat, and that’s\\nvery like a mouse, you know. But do cats eat bats, I wonder?” And here\\nAlice began to get rather sleepy, and went on saying to herself, in a\\ndreamy sort of way, “Do cats eat bats? Do cats eat bats?” and\\nsometimes, “Do bats eat cats?” for, you see, as she couldn’t answer\\neither question, it didn’t much matter which way she put it. She felt\\nthat she was dozing off, and had just begun to dream that she was\\nwalking hand in hand with Dinah, and saying to her very earnestly,\\n“Now, Dinah, tell me the truth: did you ever eat a bat?” when suddenly,\\nthump! thump! down she came upon a heap of sticks and dry leaves, and\\nthe fall was over.\",\n",
      "  \"metadata\": {\n",
      "    \"source\": \"alice_in_wonderland.md\",\n",
      "    \"chapter_number\": \"Chapter I\",\n",
      "    \"chapter_title\": \"Down the Rabbit-Hole\",\n",
      "    \"start_index\": 3895,\n",
      "    \"chunk_number\": 2,\n",
      "    \"chunk_summary\": \"Alice begins her descent by musically musing, “I wonder if I shall fall right _through_ the earth!” and jokingly asking the unseen “Please, Ma’am, is this New Zealand or Australia?” as she imagines curtseying while falling. She then turns to her absent cat Dinah, lamenting, “Dinah’ll miss me very much to-night, I should think!” and wonders aloud, “Do cats eat bats?” before drifting into a dream where she questions whether bats eat cats. The passage ends with her thumping onto a heap of sticks and dry leaves, the fall finally over.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Load and chunk the book (token-aware) + batch summarization via OpenRouter (gpt-oss-20b)\n",
    "import os, json, re, requests\n",
    "from pathlib import Path\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# --- Pydantic models for consistent metadata ---\n",
    "class ChunkMetadata(BaseModel):\n",
    "    source: str\n",
    "    chapter_number: str | None\n",
    "    chapter_title: str | None\n",
    "    start_index: int | None\n",
    "    chunk_number: int\n",
    "    chunk_summary: str\n",
    "\n",
    "class ChunkDoc(BaseModel):\n",
    "    content: str\n",
    "    metadata: ChunkMetadata\n",
    "\n",
    "# --- Summarization pipeline (OpenRouter: openai/gpt-oss-20b) ---\n",
    "class OpenRouterSummarizer:\n",
    "    def __init__(self, model=\"openai/gpt-oss-20b\", api_key=None):\n",
    "        self.model = model\n",
    "        self.api_key = api_key or os.getenv(\"OPENROUTER_API_KEY\")\n",
    "        assert self.api_key, \"OpenRouter API key not found. Set OPENROUTER_API_KEY in your .env.\"\n",
    "\n",
    "    # Keep the same call signature you used before\n",
    "    def __call__(self, texts, max_length=40, min_length=10, do_sample=False, batch_size=8):\n",
    "        url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "        results = []\n",
    "        for t in texts:\n",
    "            prompt = (\n",
    "                \"Summarize the passage in 2-3 sentences as per the content, capture the main point of the content and make sure you're not missing out on the quotes from the content.\"\n",
    "                f\"Passage:\\n{t}\\n\\nSummary:\"\n",
    "            )\n",
    "            payload = {\n",
    "                \"model\": self.model,\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"temperature\": 0.2,\n",
    "            }\n",
    "            r = requests.post(url, headers=headers, json=payload, timeout=120)\n",
    "            r.raise_for_status()\n",
    "            content = r.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            results.append({\"summary_text\": content})\n",
    "        return results\n",
    "\n",
    "# Initialize summarizer (variable name unchanged)\n",
    "summarizer = OpenRouterSummarizer(model=\"openai/gpt-oss-20b\")\n",
    "\n",
    "# --- Function: parse chapters (captures both same-line and next-line titles) ---\n",
    "def parse_chapters(text):\n",
    "    \"\"\"\n",
    "    Matches:\n",
    "      Contents lines:  'CHAPTER I. Down the Rabbit-Hole'\n",
    "      Chapter headers: 'CHAPTER I.\\nDown the Rabbit-Hole'\n",
    "    \"\"\"\n",
    "    pattern = re.compile(r\"CHAPTER\\s+([IVXLCDM]+)\\.\\s*(?:([^\\n]+)|\\n([^\\n]+))\")\n",
    "    chapters = []\n",
    "    for m in pattern.finditer(text):\n",
    "        title = (m.group(2) or m.group(3) or \"\").strip()\n",
    "        chapters.append({\n",
    "            \"start\": m.start(),\n",
    "            \"chapter_number\": f\"Chapter {m.group(1)}\",\n",
    "            \"chapter_title\": title\n",
    "        })\n",
    "    chapters.sort(key=lambda x: x[\"start\"])\n",
    "    return chapters\n",
    "\n",
    "# --- Function: split and summarize (token-aware, reliable start_index) ---\n",
    "def load_and_chunk_markdown(md_path, chunk_size=600, chunk_overlap=100, batch_size=10):\n",
    "    with open(md_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        full_text = f.read()\n",
    "\n",
    "    chapters = parse_chapters(full_text)\n",
    "\n",
    "    # Token-aware splitter with start indices:\n",
    "    # NOTE: pass add_start_index=True on the splitter (NOT on create_documents)\n",
    "    try:\n",
    "        splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            add_start_index=True\n",
    "        )\n",
    "    except TypeError:\n",
    "        # Fallback for older LangChain versions: construct directly\n",
    "        splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            add_start_index=True\n",
    "        )\n",
    "\n",
    "    # create_documents returns documents with metadata['start_index']\n",
    "    doc_objs = splitter.create_documents([full_text])\n",
    "\n",
    "    # Prepare raw chunk strings for summarizer call\n",
    "    chunks = [d.page_content for d in doc_objs]\n",
    "\n",
    "    # 🔹 Summarize chunks (OpenRouter; sequential for clarity)\n",
    "    summaries = summarizer(\n",
    "        chunks,\n",
    "        max_length=40,\n",
    "        min_length=10,\n",
    "        do_sample=False,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    docs: list[ChunkDoc] = []\n",
    "    for i, (d, summary_obj) in enumerate(zip(doc_objs, summaries)):\n",
    "        start_index = d.metadata.get(\"start_index\", None)\n",
    "        chunk = d.page_content\n",
    "        summary = summary_obj[\"summary_text\"]\n",
    "\n",
    "        # Find chapter for this chunk by position (binary search style)\n",
    "        chapter_number, chapter_title = None, None\n",
    "        if start_index is not None and chapters:\n",
    "            lo, hi, idx = 0, len(chapters)-1, -1\n",
    "            while lo <= hi:\n",
    "                mid = (lo + hi) // 2\n",
    "                if chapters[mid][\"start\"] <= start_index:\n",
    "                    idx = mid\n",
    "                    lo = mid + 1\n",
    "                else:\n",
    "                    hi = mid - 1\n",
    "            if idx >= 0:\n",
    "                chapter_number = chapters[idx][\"chapter_number\"]\n",
    "                chapter_title = chapters[idx][\"chapter_title\"]\n",
    "\n",
    "        # Create ChunkDoc with validated metadata\n",
    "        meta = ChunkMetadata(\n",
    "            source=md_path,\n",
    "            chapter_number=chapter_number,     # e.g., \"Chapter I\"\n",
    "            chapter_title=chapter_title,       # e.g., \"Down the Rabbit-Hole\"\n",
    "            start_index=start_index,\n",
    "            chunk_number=i,\n",
    "            chunk_summary=summary\n",
    "        )\n",
    "        docs.append(ChunkDoc(content=chunk, metadata=meta))\n",
    "\n",
    "    return docs\n",
    "\n",
    "# Load and chunk with batching\n",
    "print(\"⚡ Summarizing chunks with OpenRouter gpt-oss-20b (token-aware splitting)...\")\n",
    "docs = load_and_chunk_markdown(\"alice_in_wonderland.md\", batch_size=8)\n",
    "\n",
    "# #printing\n",
    "print(\"### Example 3 Chunks ###\")\n",
    "for d in docs[:3]:\n",
    "    print(d.model_dump_json(indent=2))  # ✅ Pydantic pretty JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01228159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from_texts() takes each chunk from texts=[d[\"content\"] for d in docs].\\nFor each chunk, it calls embeddings.embed_text(text) under the hood.\\nembed_text converts the chunk into a high-dimensional vector (embedding).\\nThese vectors are then stored in Chroma along with your metadata. '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from_texts() takes each chunk from texts=[d[\"content\"] for d in docs].\n",
    "For each chunk, it calls embeddings.embed_text(text) under the hood.\n",
    "embed_text converts the chunk into a high-dimensional vector (embedding).\n",
    "These vectors are then stored in Chroma along with your metadata. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "773f08b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Vector DB Info ###\n",
      "Persist dir: ./chroma_store\n",
      "Total vectors stored: 616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/52/ns3sdnhj22n2q3hsq7mpbgv40000gn/T/ipykernel_79337/527124548.py:15: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: Build embeddings + vectorstore (persistent Chroma; cosine)\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "vectordb = Chroma.from_texts(\n",
    "    texts=[d.content for d in docs],                       # Pydantic -> attribute\n",
    "    embedding=embeddings,\n",
    "    metadatas=[d.metadata.model_dump() for d in docs],     # Pydantic -> dict\n",
    "    persist_directory=\"./chroma_store\",                    # persist to disk\n",
    "    collection_name=\"alice\",\n",
    "    collection_metadata={\"hnsw:space\": \"cosine\"}           # cosine similarity\n",
    ")\n",
    "vectordb.persist()\n",
    "\n",
    "# #printing\n",
    "print(\"### Vector DB Info ###\")\n",
    "print(\"Persist dir:\", \"./chroma_store\")\n",
    "print(\"Total vectors stored:\", vectordb._collection.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c32652d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Multi-Query Expansions ###\n",
      "Original: Why did Alice follow the White Rabbit and what happened immediately after she fell down the rabbit hole?\n",
      "\n",
      "Expansions:\n",
      "{\n",
      "  \"items\": [\n",
      "    \"What motivated Alice to pursue the White Rabbit, and what events transpired right after her descent into the rabbit hole?\",\n",
      "    \"Could you explain Alice's reason for chasing the White Rabbit, and describe the immediate aftermath of her fall down the rabbit hole?\",\n",
      "    \"What prompted Alice to go after the White Rabbit, and what occurred the moment she plunged into the rabbit hole?\",\n",
      "    \"Detail Alice's rationale for trailing the White Rabbit, and recount the initial occurrences following her tumble into the rabbit hole.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# STEP 6: Multi-query expansions using Gemini\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from typing import List\n",
    "import json\n",
    "\n",
    "class Expansions(BaseModel):\n",
    "    items: List[str] = Field(..., min_items=1, description=\"List of paraphrased questions\")\n",
    "    \n",
    "    @field_validator('items')\n",
    "    def validate_items(cls, v):\n",
    "        if not all(isinstance(item, str) and len(item.strip()) > 0 for item in v):\n",
    "            raise ValueError(\"All items must be non-empty strings\")\n",
    "        return [item.strip() for item in v]\n",
    "\n",
    "def expand_queries(llm, question, n=4):\n",
    "    \"\"\"\n",
    "    Uses Gemini to generate diverse paraphrases of the input question.\n",
    "    Returns a list of exactly n paraphrased questions, validated by Pydantic.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        f\"Generate exactly {n} diverse paraphrases of the question below.\\n\"\n",
    "        \"Your response should be ONLY a valid JSON object with this exact format:\\n\"\n",
    "        '{\"items\": [\"paraphrase1\", \"paraphrase2\", ...]}\\n\\n'\n",
    "        f\"Question: {question}\\n\\n\"\n",
    "        \"Remember: Return ONLY the JSON object, no other text.\"\n",
    "    )\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    try:\n",
    "        # Try to parse the response as JSON\n",
    "        json_str = response.content.strip()\n",
    "        # Find JSON object if it's embedded in other text\n",
    "        start = json_str.find('{')\n",
    "        end = json_str.rfind('}') + 1\n",
    "        if start >= 0 and end > start:\n",
    "            json_str = json_str[start:end]\n",
    "        result = json.loads(json_str)\n",
    "        \n",
    "        # Validate with Pydantic and ensure exactly n items\n",
    "        items = result.get('items', [])\n",
    "        # If we have too few items, pad with the original question\n",
    "        while len(items) < n:\n",
    "            items.append(question)\n",
    "        # If we have too many items, take the first n\n",
    "        items = items[:n]\n",
    "        \n",
    "        # Final validation with Pydantic\n",
    "        expansions = Expansions(items=items)\n",
    "        return expansions.items\n",
    "        \n",
    "    except (json.JSONDecodeError, KeyError, IndexError, AttributeError) as e:\n",
    "        # If JSON parsing fails, create a list with the original question repeated\n",
    "        items = [question] * n\n",
    "        expansions = Expansions(items=items)\n",
    "        return expansions.items\n",
    "\n",
    "# keep your Gemini client as-is (used for answering later)\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm_gemini = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.3,\n",
    "    google_api_key=GOOGLE_API_KEY\n",
    ")\n",
    "\n",
    "user_question = \"Why did Alice follow the White Rabbit and what happened immediately after she fell down the rabbit hole?\"\n",
    "expansions = expand_queries(llm_gemini, user_question)\n",
    "\n",
    "# #printing\n",
    "print(\"### Multi-Query Expansions ###\")\n",
    "print(f\"Original: {user_question}\")\n",
    "print(\"\\nExpansions:\")\n",
    "print(json.dumps({\"items\": expansions}, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "515ab47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Retrieved Candidates ###\n",
      "{\n",
      "  \"results\": [\n",
      "    {\n",
      "      \"question\": \"Why did Alice follow the White Rabbit and what happened immediately after she fell down the rabbit hole?\",\n",
      "      \"score\": 0.2551690936088562,\n",
      "      \"content\": \"So she was considering in her own mind (as well as she could, for the\\nhot day made her feel very sleepy and stupid), whether the pleasure of\\nmaking a daisy-chain would be worth the trouble of getting up and\\npicking the daisies, when suddenly a White Rabbit with pink eyes ran\\nclose by her.\\n\\nThere was nothing so _very_ remarkable in that; nor did Alice think it\\nso _very_ much out of the way to hear the Rabbit say to itself, “Oh\\ndear! Oh dear! I shall be late!” (when she thought it over afterwards,\\nit occurred to her that she ought to have wondered at this, but at the\\ntime it all seemed quite natural); but when the Rabbit actually _took a\\nwatch out of its waistcoat-pocket_, and looked at it, and then hurried\\non, Alice started to her feet, for it flashed across her mind that she\\nhad never before seen a rabbit with either a waistcoat-pocket, or a\\nwatch to take out of it, and burning with curiosity, she ran across the\\nfield after it, and fortunately was just in time to see it pop down a\\nlarge rabbit-hole under the hedge.\\n\\nIn another moment down went Alice after it, never once considering how\\nin the world she was to get out again.\\n\\nThe rabbit-hole went straight on like a tunnel for some way, and then\\ndipped suddenly down, so suddenly that Alice had not a moment to think\\nabout stopping herself before she found herself falling down a very\\ndeep well.\\n\\nEither the well was very deep, or she fell very slowly, for she had\\nplenty of time as she went down to look about her and to wonder what\\nwas going to happen next. First, she tried to look down and make out\\nwhat she was coming to, but it was too dark to see anything; then she\\nlooked at the sides of the well, and noticed that they were filled with\\ncupboards and book-shelves; here and there she saw maps and pictures\\nhung upon pegs. She took down a jar from one of the shelves as she\\npassed; it was labelled “ORANGE MARMALADE”, but to her great\\ndisappointment it was empty: she did not like to drop the jar for fear\\nof killing somebody underneath, so managed to put it into one of the\\ncupboards as she fell past it.\",\n",
      "      \"metadata\": {\n",
      "        \"source\": \"alice_in_wonderland.md\",\n",
      "        \"chapter_number\": null,\n",
      "        \"chapter_title\": null,\n",
      "        \"position\": -1,\n",
      "        \"chunk_number\": 1,\n",
      "        \"chunk_summary\": \"Alice, feeling sleepy on a hot day, muses whether the pleasure of making a daisy‑chain is worth the trouble of picking daisies when a White Rabbit with pink eyes rushes past her, exclaiming “Oh dear! Oh dear! I shall be late!” and pulling a watch from its waistcoat‑pocket—an odd sight that sparks her curiosity and leads her to chase the rabbit down a large rabbit‑hole. She falls into a deep well, where she notices cupboards and bookshelves lining the walls, and even picks up a jar labeled “ORANGE MARMALADE,” though it is empty, and she carefully places it back to avoid disturbing anyone below.\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"question\": \"What motivated Alice to pursue the White Rabbit, and what events transpired right after her descent into the rabbit hole?\",\n",
      "      \"score\": 0.26950955390930176,\n",
      "      \"content\": \"**_ START OF THE PROJECT GUTENBERG EBOOK ALICE'S ADVENTURES IN WONDERLAND _**\\n\\nContents\\n\\nCHAPTER I. Down the Rabbit-Hole\\nCHAPTER II. The Pool of Tears\\nCHAPTER III. A Caucus-Race and a Long Tale\\nCHAPTER IV. The Rabbit Sends in a Little Bill\\nCHAPTER V. Advice from a Caterpillar\\nCHAPTER VI. Pig and Pepper\\nCHAPTER VII. A Mad Tea-Party\\nCHAPTER VIII. The Queen’s Croquet-Ground\\nCHAPTER IX. The Mock Turtle’s Story\\nCHAPTER X. The Lobster Quadrille\\nCHAPTER XI. Who Stole the Tarts?\\nCHAPTER XII. Alice’s Evidence\\n\\nCHAPTER I.\\nDown the Rabbit-Hole\\n\\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once or twice she had peeped into\\nthe book her sister was reading, but it had no pictures or\\nconversations in it, “and what is the use of a book,” thought Alice\\n“without pictures or conversations?”\\n\\nSo she was considering in her own mind (as well as she could, for the\\nhot day made her feel very sleepy and stupid), whether the pleasure of\\nmaking a daisy-chain would be worth the trouble of getting up and\\npicking the daisies, when suddenly a White Rabbit with pink eyes ran\\nclose by her.\\n\\nThere was nothing so _very_ remarkable in that; nor did Alice think it\\nso _very_ much out of the way to hear the Rabbit say to itself, “Oh\\ndear! Oh dear! I shall be late!” (when she thought it over afterwards,\\nit occurred to her that she ought to have wondered at this, but at the\\ntime it all seemed quite natural); but when the Rabbit actually _took a\\nwatch out of its waistcoat-pocket_, and looked at it, and then hurried\\non, Alice started to her feet, for it flashed across her mind that she\\nhad never before seen a rabbit with either a waistcoat-pocket, or a\\nwatch to take out of it, and burning with curiosity, she ran across the\\nfield after it, and fortunately was just in time to see it pop down a\\nlarge rabbit-hole under the hedge.\\n\\nIn another moment down went Alice after it, never once considering how\\nin the world she was to get out again.\\n\\nThe rabbit-hole went straight on like a tunnel for some way, and then\\ndipped suddenly down, so suddenly that Alice had not a moment to think\\nabout stopping herself before she found herself falling down a very\\ndeep well.\\n\\nEither the well was very deep, or she fell very slowly, for she had\\nplenty of time as she went down to look about her and to wonder what\\nwas going to happen next. First, she tried to look down and make out\\nwhat she was coming to, but it was too dark to see anything; then she\\nlooked at the sides of the well, and noticed that they were filled with\\ncupboards and book-shelves; here and there she saw maps and pictures\\nhung upon pegs. She took down a jar from one of the shelves as she\\npassed; it was labelled “ORANGE MARMALADE”, but to her great\\ndisappointment it was empty: she did not like to drop the jar for fear\\nof killing somebody underneath, so managed to put it into one of the\\ncupboards as she fell past it.\",\n",
      "      \"metadata\": {\n",
      "        \"source\": \"alice_in_wonderland.md\",\n",
      "        \"chapter_number\": null,\n",
      "        \"chapter_title\": null,\n",
      "        \"position\": 1,\n",
      "        \"chunk_number\": 0,\n",
      "        \"chunk_summary\": \"Alice, bored beside her sister, spots a white rabbit wearing a waistcoat and carrying a watch, and her curiosity leads her to chase it into a rabbit‑hole. She falls down a deep, dark tunnel lined with cupboards and bookshelves, where she discovers an empty jar labeled “ORANGE MARMALADE.”\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# STEP 7: Retrieve chunks (cosine similarity) for original + expansions\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "class RetrievedMetadata(BaseModel):\n",
    "    source: str\n",
    "    chapter_number: Optional[str] = None\n",
    "    chapter_title: Optional[str] = None\n",
    "    position: Optional[int] = Field(None, alias=\"start_index\")\n",
    "    chunk_number: Optional[int] = None\n",
    "    chunk_summary: Optional[str] = None\n",
    "\n",
    "class RetrievedChunk(BaseModel):\n",
    "    question: str\n",
    "    score: float\n",
    "    content: str\n",
    "    metadata: RetrievedMetadata\n",
    "\n",
    "class RetrievalResults(BaseModel):\n",
    "    results: List[RetrievedChunk]\n",
    "\n",
    "def retrieve_candidates(vectordb, queries, per_query_k=5):\n",
    "    results = []\n",
    "    seen = set()\n",
    "    for q in queries:\n",
    "        hits = vectordb.similarity_search_with_score(q, k=per_query_k)\n",
    "        for doc, score in hits:\n",
    "            key = (doc.metadata.get(\"start_index\"), doc.metadata.get(\"chunk_number\"))\n",
    "            if key not in seen:\n",
    "                seen.add(key)\n",
    "                # Create a structured chunk with Pydantic\n",
    "                chunk = RetrievedChunk(\n",
    "                    question=q,\n",
    "                    score=float(score),  # Ensure score is float\n",
    "                    content=doc.page_content,\n",
    "                    metadata=RetrievedMetadata(**doc.metadata)\n",
    "                )\n",
    "                results.append(chunk)\n",
    "    return RetrievalResults(results=results)\n",
    "\n",
    "queries = [user_question] + expansions\n",
    "candidates = retrieve_candidates(vectordb, queries, per_query_k=5)\n",
    "\n",
    "# Printing in structured JSON format\n",
    "print(\"### Retrieved Candidates ###\")\n",
    "print(candidates.model_dump_json(indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05f4d1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Top Reranked Docs ###\n",
      "{\n",
      "  \"results\": [\n",
      "    {\n",
      "      \"content\": \"So she was considering in her own mind (as well as she could, for the\\nhot day made her feel very sleepy and stupid), whether the pleasure of\\nmaking a daisy-chain would be worth the trouble of getting up and\\npicking the daisies, when suddenly a White Rabbit with pink eyes ran\\nclose by her.\\n\\nThere was nothing so _very_ remarkable in that; nor did Alice think it\\nso _very_ much out of the way to hear the Rabbit say to itself, “Oh\\ndear! Oh dear! I shall be late!” (when she thought it over afterwards,\\nit occurred to her that she ought to have wondered at this, but at the\\ntime it all seemed quite natural); but when the Rabbit actually _took a\\nwatch out of its waistcoat-pocket_, and looked at it, and then hurried\\non, Alice started to her feet, for it flashed across her mind that she\\nhad never before seen a rabbit with either a waistcoat-pocket, or a\\nwatch to take out of it, and burning with curiosity, she ran across the\\nfield after it, and fortunately was just in time to see it pop down a\\nlarge rabbit-hole under the hedge.\\n\\nIn another moment down went Alice after it, never once considering how\\nin the world she was to get out again.\\n\\nThe rabbit-hole went straight on like a tunnel for some way, and then\\ndipped suddenly down, so suddenly that Alice had not a moment to think\\nabout stopping herself before she found herself falling down a very\\ndeep well.\\n\\nEither the well was very deep, or she fell very slowly, for she had\\nplenty of time as she went down to look about her and to wonder what\\nwas going to happen next. First, she tried to look down and make out\\nwhat she was coming to, but it was too dark to see anything; then she\\nlooked at the sides of the well, and noticed that they were filled with\\ncupboards and book-shelves; here and there she saw maps and pictures\\nhung upon pegs. She took down a jar from one of the shelves as she\\npassed; it was labelled “ORANGE MARMALADE”, but to her great\\ndisappointment it was empty: she did not like to drop the jar for fear\\nof killing somebody underneath, so managed to put it into one of the\\ncupboards as she fell past it.\",\n",
      "      \"metadata\": {\n",
      "        \"source\": \"alice_in_wonderland.md\",\n",
      "        \"chapter_number\": null,\n",
      "        \"chapter_title\": null,\n",
      "        \"position\": null,\n",
      "        \"chunk_number\": 1,\n",
      "        \"chunk_summary\": \"Alice, feeling sleepy on a hot day, muses whether the pleasure of making a daisy‑chain is worth the trouble of picking daisies when a White Rabbit with pink eyes rushes past her, exclaiming “Oh dear! Oh dear! I shall be late!” and pulling a watch from its waistcoat‑pocket—an odd sight that sparks her curiosity and leads her to chase the rabbit down a large rabbit‑hole. She falls into a deep well, where she notices cupboards and bookshelves lining the walls, and even picks up a jar labeled “ORANGE MARMALADE,” though it is empty, and she carefully places it back to avoid disturbing anyone below.\"\n",
      "      },\n",
      "      \"rerank_score\": 2.939453125\n",
      "    },\n",
      "    {\n",
      "      \"content\": \"**_ START OF THE PROJECT GUTENBERG EBOOK ALICE'S ADVENTURES IN WONDERLAND _**\\n\\nContents\\n\\nCHAPTER I. Down the Rabbit-Hole\\nCHAPTER II. The Pool of Tears\\nCHAPTER III. A Caucus-Race and a Long Tale\\nCHAPTER IV. The Rabbit Sends in a Little Bill\\nCHAPTER V. Advice from a Caterpillar\\nCHAPTER VI. Pig and Pepper\\nCHAPTER VII. A Mad Tea-Party\\nCHAPTER VIII. The Queen’s Croquet-Ground\\nCHAPTER IX. The Mock Turtle’s Story\\nCHAPTER X. The Lobster Quadrille\\nCHAPTER XI. Who Stole the Tarts?\\nCHAPTER XII. Alice’s Evidence\\n\\nCHAPTER I.\\nDown the Rabbit-Hole\\n\\nAlice was beginning to get very tired of sitting by her sister on the\\nbank, and of having nothing to do: once or twice she had peeped into\\nthe book her sister was reading, but it had no pictures or\\nconversations in it, “and what is the use of a book,” thought Alice\\n“without pictures or conversations?”\\n\\nSo she was considering in her own mind (as well as she could, for the\\nhot day made her feel very sleepy and stupid), whether the pleasure of\\nmaking a daisy-chain would be worth the trouble of getting up and\\npicking the daisies, when suddenly a White Rabbit with pink eyes ran\\nclose by her.\\n\\nThere was nothing so _very_ remarkable in that; nor did Alice think it\\nso _very_ much out of the way to hear the Rabbit say to itself, “Oh\\ndear! Oh dear! I shall be late!” (when she thought it over afterwards,\\nit occurred to her that she ought to have wondered at this, but at the\\ntime it all seemed quite natural); but when the Rabbit actually _took a\\nwatch out of its waistcoat-pocket_, and looked at it, and then hurried\\non, Alice started to her feet, for it flashed across her mind that she\\nhad never before seen a rabbit with either a waistcoat-pocket, or a\\nwatch to take out of it, and burning with curiosity, she ran across the\\nfield after it, and fortunately was just in time to see it pop down a\\nlarge rabbit-hole under the hedge.\\n\\nIn another moment down went Alice after it, never once considering how\\nin the world she was to get out again.\\n\\nThe rabbit-hole went straight on like a tunnel for some way, and then\\ndipped suddenly down, so suddenly that Alice had not a moment to think\\nabout stopping herself before she found herself falling down a very\\ndeep well.\\n\\nEither the well was very deep, or she fell very slowly, for she had\\nplenty of time as she went down to look about her and to wonder what\\nwas going to happen next. First, she tried to look down and make out\\nwhat she was coming to, but it was too dark to see anything; then she\\nlooked at the sides of the well, and noticed that they were filled with\\ncupboards and book-shelves; here and there she saw maps and pictures\\nhung upon pegs. She took down a jar from one of the shelves as she\\npassed; it was labelled “ORANGE MARMALADE”, but to her great\\ndisappointment it was empty: she did not like to drop the jar for fear\\nof killing somebody underneath, so managed to put it into one of the\\ncupboards as she fell past it.\",\n",
      "      \"metadata\": {\n",
      "        \"source\": \"alice_in_wonderland.md\",\n",
      "        \"chapter_number\": null,\n",
      "        \"chapter_title\": null,\n",
      "        \"position\": null,\n",
      "        \"chunk_number\": 0,\n",
      "        \"chunk_summary\": \"Alice, bored beside her sister, spots a white rabbit wearing a waistcoat and carrying a watch, and her curiosity leads her to chase it into a rabbit‑hole. She falls down a deep, dark tunnel lined with cupboards and bookshelves, where she discovers an empty jar labeled “ORANGE MARMALADE.”\"\n",
      "      },\n",
      "      \"rerank_score\": 2.02734375\n",
      "    }\n",
      "  ],\n",
      "  \"original_question\": \"Why did Alice follow the White Rabbit and what happened immediately after she fell down the rabbit hole?\",\n",
      "  \"model_name\": \"BAAI/bge-reranker-base\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# STEP 8: Rerank candidates with cross-encoder (dedupe; take top 5)\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "class RerankedMetadata(BaseModel):\n",
    "    source: str\n",
    "    chapter_number: Optional[str] = None\n",
    "    chapter_title: Optional[str] = None\n",
    "    position: Optional[int] = Field(None, alias=\"start_index\")\n",
    "    chunk_number: Optional[int] = None\n",
    "    chunk_summary: Optional[str] = None\n",
    "\n",
    "class RerankedDocument(BaseModel):\n",
    "    content: str\n",
    "    metadata: RerankedMetadata\n",
    "    rerank_score: float\n",
    "    \n",
    "class RerankedResults(BaseModel):\n",
    "    results: List[RerankedDocument]\n",
    "    original_question: str\n",
    "    model_name: str = \"BAAI/bge-reranker-base\"\n",
    "\n",
    "reranker = FlagReranker(\"BAAI/bge-reranker-base\", use_fp16=True)\n",
    "\n",
    "def rerank_candidates(question, candidates, top_n=5):\n",
    "    # Create pairs for reranking\n",
    "    pairs = [[question, doc.content] for doc in candidates.results]\n",
    "    scores = reranker.compute_score(pairs)\n",
    "    reranked = sorted(zip(candidates.results, scores), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Deduplicate by start_index\n",
    "    seen = set()\n",
    "    top_docs = []\n",
    "    for doc, rerank_score in reranked:\n",
    "        sid = doc.metadata.position  # Using the position field we defined\n",
    "        if sid not in seen:\n",
    "            seen.add(sid)\n",
    "            # Create structured document\n",
    "            reranked_doc = RerankedDocument(\n",
    "                content=doc.content,\n",
    "                metadata=RerankedMetadata(**doc.metadata.model_dump()),\n",
    "                rerank_score=float(rerank_score)\n",
    "            )\n",
    "            top_docs.append(reranked_doc)\n",
    "        if len(top_docs) == top_n:\n",
    "            break\n",
    "            \n",
    "    return RerankedResults(\n",
    "        results=top_docs,\n",
    "        original_question=question\n",
    "    )\n",
    "\n",
    "top_docs = rerank_candidates(user_question, candidates, top_n=5)\n",
    "\n",
    "# Printing in structured JSON format\n",
    "print(\"### Top Reranked Docs ###\")\n",
    "print(top_docs.model_dump_json(indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69c6523f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### FINAL ANSWER (Structured) ###\n",
      "{\n",
      "  \"answer\": \"Alice followed the White Rabbit because she was overcome with curiosity. She was astonished to see a rabbit take a watch from its waistcoat-pocket, an sight she had never encountered before. Immediately after she went down the rabbit hole, it turned into a very deep well, and she found herself falling slowly. During her descent, she observed that the sides of the well were filled with various objects like cupboards, bookshelves, maps, and pictures.\",\n",
      "  \"citations\": [\n",
      "    {\n",
      "      \"source\": \"alice_in_wonderland.md\",\n",
      "      \"chapter_number\": null,\n",
      "      \"chapter_title\": null,\n",
      "      \"position\": null,\n",
      "      \"chunk_number\": 1\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"alice_in_wonderland.md\",\n",
      "      \"chapter_number\": null,\n",
      "      \"chapter_title\": null,\n",
      "      \"position\": null,\n",
      "      \"chunk_number\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"context_headers\": [\n",
      "    \"[Source: alice_in_wonderland.md | Chapter None None | Position=None | Chunk 1]\",\n",
      "    \"[Source: alice_in_wonderland.md | Chapter None None | Position=None | Chunk 0]\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# STEP 9: Build context and answer with Gemini (final result with structured output)\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "# Pydantic models for structured output\n",
    "class Citation(BaseModel):\n",
    "    source: str\n",
    "    chapter_number: Optional[str] = None\n",
    "    chapter_title: Optional[str] = None\n",
    "    position: Optional[int] = Field(None, alias=\"start_index\")\n",
    "    chunk_number: Optional[int] = None\n",
    "\n",
    "class GeminiResponse(BaseModel):\n",
    "    answer: str = Field(..., description=\"The answer from Gemini\")\n",
    "    citations: List[Citation] = Field(default_factory=list, description=\"Citations from the context\")\n",
    "    context_headers: List[str] = Field(default_factory=list, description=\"Headers from the context\")\n",
    "\n",
    "def build_context(docs):\n",
    "    parts = []\n",
    "    for doc in docs.results:  # Using the structured results from Step 8\n",
    "        m = doc.metadata\n",
    "        header = f\"[Source: {m.source} | Chapter {m.chapter_number} {m.chapter_title} | Position={m.position} | Chunk {m.chunk_number}]\"\n",
    "        parts.append(header + \"\\n\" + doc.content)\n",
    "    return \"\\n\\n\".join(parts)\n",
    "\n",
    "context = build_context(top_docs)\n",
    "\n",
    "# Get headers for citations\n",
    "headers = []\n",
    "citations = []\n",
    "for doc in top_docs.results:  # Using the structured results from Step 8\n",
    "    m = doc.metadata\n",
    "    headers.append(f\"[Source: {m.source} | Chapter {m.chapter_number} {m.chapter_title} | Position={m.position} | Chunk {m.chunk_number}]\")\n",
    "    citations.append(Citation(\n",
    "        source=m.source,\n",
    "        chapter_number=m.chapter_number,\n",
    "        chapter_title=m.chapter_title,\n",
    "        start_index=m.position,  # Using position as start_index\n",
    "        chunk_number=m.chunk_number\n",
    "    ))\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant. \n",
    "Answer the user question using ONLY the provided context.\n",
    "Read the chunk summary carefully and if it matches with the question then check the chunk content and answer the question.\n",
    "Expand the answer into at least 2–3 sentences and don't use quotes from the content unless the question is asking for the quotes.\n",
    "\n",
    "Question: {question}\n",
    "Context:\n",
    "{context}\n",
    "\"\"\")\n",
    "\n",
    "answer = llm_gemini.invoke(prompt.format(question=user_question, context=context))\n",
    "\n",
    "# Create structured response\n",
    "response = GeminiResponse(\n",
    "    answer=answer.content,\n",
    "    citations=citations,\n",
    "    context_headers=headers\n",
    ")\n",
    "\n",
    "# Printing in structured JSON format\n",
    "print(\"### FINAL ANSWER (Structured) ###\")\n",
    "print(response.model_dump_json(indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
